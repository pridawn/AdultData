{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_loader import *\n",
    "\n",
    "# training_data = load_train_data(\"adult_data.csv\")[0].values\n",
    "# validation_data = load_train_data(\"adult_data.csv\")[1].values\n",
    "\n",
    "# Xtr,Ytr = training_data[:,0:14], training_data[:,-1]\n",
    "# Xva,Yva = validation_data[:,0:14], validation_data[:,-1]\n",
    "\n",
    "Xtr,Xva=load_train_data(\"adult_data.csv\")\n",
    "Xte=load_test_data(\"adult_test.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "POS_STR = ' >50K'\n",
    "\n",
    "train_file_path='adult_data.csv'\n",
    "test_file_path='adult_test.csv'\n",
    "\n",
    "\n",
    "\n",
    "def load_train_data(train_file_path, valid_rate=0.25, is_df=True):\n",
    "    data_frame = pd.read_csv(train_file_path).sample(frac=1, random_state=11)\n",
    "    np.random.seed(11)\n",
    "    mask = np.random.rand(len(data_frame)) < 1 - valid_rate\n",
    "    train_df, valid_df = data_frame.iloc[mask, :], data_frame.iloc[~mask, :]\n",
    "    if is_df:\n",
    "        return train_df, valid_df\n",
    "\n",
    "    train_labels = [1 if x == POS_STR else 0 for x in train_df.iloc[:, 14].values]\n",
    "    valid_labels = [1 if x == POS_STR else 0 for x in valid_df.iloc[:, 14].values]\n",
    "    return train_df.iloc[:, :14].values, np.array(train_labels), valid_df.iloc[:, :14].values, np.array(valid_labels)\n",
    "\n",
    "\n",
    "def load_test_data(test_file_path, is_df=True):\n",
    "    data_frame = pd.read_csv(test_file_path)\n",
    "    if is_df:\n",
    "        return data_frame\n",
    "\n",
    "    test_labels = [1 if x == POS_STR else 0 for x in data_frame.iloc[:, 14].values]\n",
    "    return data_frame.iloc[:, :14].values, np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078252</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.080028</td>\n",
       "      <td>0.053824</td>\n",
       "      <td>0.067805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>-0.078252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.012357</td>\n",
       "      <td>-0.018081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0.030518</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.124092</td>\n",
       "      <td>0.078441</td>\n",
       "      <td>0.154133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>0.080028</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>0.124092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032003</td>\n",
       "      <td>0.081663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>0.053824</td>\n",
       "      <td>-0.012357</td>\n",
       "      <td>0.078441</td>\n",
       "      <td>-0.032003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>0.067805</td>\n",
       "      <td>-0.018081</td>\n",
       "      <td>0.154133</td>\n",
       "      <td>0.081663</td>\n",
       "      <td>0.051736</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "age             1.000000 -0.078252       0.030518      0.080028      0.053824   \n",
       "fnlwgt         -0.078252  1.000000      -0.040856     -0.000322     -0.012357   \n",
       "education_num   0.030518 -0.040856       1.000000      0.124092      0.078441   \n",
       "capital_gain    0.080028 -0.000322       0.124092      1.000000     -0.032003   \n",
       "capital_loss    0.053824 -0.012357       0.078441     -0.032003      1.000000   \n",
       "hours_per_week  0.067805 -0.018081       0.154133      0.081663      0.051736   \n",
       "\n",
       "                hours_per_week  \n",
       "age                   0.067805  \n",
       "fnlwgt               -0.018081  \n",
       "education_num         0.154133  \n",
       "capital_gain          0.081663  \n",
       "capital_loss          0.051736  \n",
       "hours_per_week        1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr,Xva=load_train_data(train_file_path)\n",
    "Xte=load_test_data(test_file_path)\n",
    "Xtr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.drop('education',axis=1,inplace=True)\n",
    "Xva.drop('education',axis=1,inplace=True)\n",
    "Xte.drop('education',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.drop('fnlwgt',axis=1,inplace=True)\n",
    "Xva.drop('fnlwgt',axis=1,inplace=True)\n",
    "Xte.drop('fnlwgt',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_onehot_features(X,featureList):\n",
    "    for feature in featureList:\n",
    "        get_dummy_features= pd.get_dummies(X[feature])\n",
    "        X=pd.concat([X,get_dummy_features],axis=1)\n",
    "    return X  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr['income'] = Xtr['income'].map( {' <=50K':0, ' >50K':1} )\n",
    "\n",
    "Xte['income'] = Xte['income'].map( {' <=50K.':0, ' >50K.':1} )\n",
    "\n",
    "Xva['income'] = Xva['income'].map( {' <=50K':0, ' >50K':1} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.columns = [\n",
    "   \"Age\", \"WorkClass\", 'EducationNum',\n",
    "   'MaritalStatus', 'Occupation', 'Relationship', 'Race', 'Gender',\n",
    "   'CapitalGain', 'CapitalLoss', 'HoursPerWeek', 'NativeCountry', 'Income'\n",
    "]\n",
    "Xva.columns = [\n",
    "   \"Age\", \"WorkClass\", 'EducationNum',\n",
    "   'MaritalStatus', 'Occupation', 'Relationship', 'Race', 'Gender',\n",
    "   'CapitalGain', 'CapitalLoss', 'HoursPerWeek', 'NativeCountry', 'Income'\n",
    "]\n",
    "Xte.columns = [\n",
    "   \"Age\", \"WorkClass\", 'EducationNum',\n",
    "   'MaritalStatus', 'Occupation', 'Relationship', 'Race', 'Gender',\n",
    "   'CapitalGain', 'CapitalLoss', 'HoursPerWeek', 'NativeCountry', 'Income'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert income to 0 and 1\n",
    "Ytr = Xtr[\"Income\"].values\n",
    "Xtr.drop(\"Income\", axis=1, inplace=True,)\n",
    "# Convert income to 0 and 1\n",
    "Yva = Xva[\"Income\"].values\n",
    "Xva.drop(\"Income\", axis=1, inplace=True,)\n",
    "# Convert income to 0 and 1\n",
    "Yte = Xte[\"Income\"].values\n",
    "Xte.drop(\"Income\", axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contiCol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3ee64e3d998b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Mean of the features {np.mean(Xtr[contiCol],axis=0)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Minimum of the features {np.min(Xtr[contiCol],axis=0)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Maximum of the features {np.max(Xtr[contiCol],axis=0)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Variance of the features {np.var(Xtr[contiCol],axis=0)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'contiCol' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Mean of the features {np.mean(Xtr[contiCol],axis=0)}\")\n",
    "print(f\"Minimum of the features {np.min(Xtr[contiCol],axis=0)}\")\n",
    "print(f\"Maximum of the features {np.max(Xtr[contiCol],axis=0)}\")\n",
    "print(f\"Variance of the features {np.var(Xtr[contiCol],axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.Age = Xtr.Age.astype(float)\n",
    "# Xtr.FnlWgt = Xtr.FnlWgt.astype(float)\n",
    "Xtr.EducationNum = Xtr.EducationNum.astype(float)\n",
    "Xtr.HoursPerWeek = Xtr.HoursPerWeek.astype(float)\n",
    "\n",
    "Xva.Age = Xva.Age.astype(float)\n",
    "# Xva.FnlWgt = Xva.FnlWgt.astype(float)\n",
    "Xva.EducationNum = Xva.EducationNum.astype(float)\n",
    "Xva.HoursPerWeek = Xva.HoursPerWeek.astype(float)\n",
    "\n",
    "Xte.Age = Xte.Age.astype(float)\n",
    "# Xte.FnlWgt = Xte.FnlWgt.astype(float)\n",
    "Xte.EducationNum = Xte.EducationNum.astype(float)\n",
    "Xte.HoursPerWeek = Xte.HoursPerWeek.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = pd.get_dummies(Xtr, columns=[\n",
    "   \"WorkClass\",\n",
    "   'MaritalStatus', 'Occupation', 'Relationship', 'Race', 'Gender', 'NativeCountry',\n",
    "])\n",
    "\n",
    "Xva = pd.get_dummies(Xva, columns=[\n",
    "   \"WorkClass\",\n",
    "   'MaritalStatus', 'Occupation', 'Relationship', 'Race', 'Gender', 'NativeCountry',\n",
    "])\n",
    "\n",
    "Xte = pd.get_dummies(Xte, columns=[\n",
    "   \"WorkClass\",\n",
    "   'MaritalStatus', 'Occupation', 'Relationship', 'Race', 'Gender', 'NativeCountry',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva.insert(loc=65, column='NativeCountry_ Holand_Netherlands', value=0)\n",
    "Xte.insert(loc=65, column='NativeCountry_ Holand_Netherlands', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24413, 91)\n",
      "(16281, 91)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'EducationNum', 'CapitalGain', 'CapitalLoss', 'HoursPerWeek',\n",
      "       'WorkClass_ ?', 'WorkClass_ Federal_gov', 'WorkClass_ Local_gov',\n",
      "       'WorkClass_ Never_worked', 'WorkClass_ Private',\n",
      "       'WorkClass_ Self_emp_inc', 'WorkClass_ Self_emp_not_inc',\n",
      "       'WorkClass_ State_gov', 'WorkClass_ Without_pay',\n",
      "       'MaritalStatus_ Divorced', 'MaritalStatus_ Married_AF_spouse',\n",
      "       'MaritalStatus_ Married_civ_spouse',\n",
      "       'MaritalStatus_ Married_spouse_absent', 'MaritalStatus_ Never_married',\n",
      "       'MaritalStatus_ Separated', 'MaritalStatus_ Widowed', 'Occupation_ ?',\n",
      "       'Occupation_ Adm_clerical', 'Occupation_ Armed_Forces',\n",
      "       'Occupation_ Craft_repair', 'Occupation_ Exec_managerial',\n",
      "       'Occupation_ Farming_fishing', 'Occupation_ Handlers_cleaners',\n",
      "       'Occupation_ Machine_op_inspct', 'Occupation_ Other_service',\n",
      "       'Occupation_ Priv_house_serv', 'Occupation_ Prof_specialty',\n",
      "       'Occupation_ Protective_serv', 'Occupation_ Sales',\n",
      "       'Occupation_ Tech_support', 'Occupation_ Transport_moving',\n",
      "       'Relationship_ Husband', 'Relationship_ Not_in_family',\n",
      "       'Relationship_ Other_relative', 'Relationship_ Own_child',\n",
      "       'Relationship_ Unmarried', 'Relationship_ Wife',\n",
      "       'Race_ Amer_Indian_Eskimo', 'Race_ Asian_Pac_Islander', 'Race_ Black',\n",
      "       'Race_ Other', 'Race_ White', 'Gender_ Female', 'Gender_ Male',\n",
      "       'NativeCountry_ ?', 'NativeCountry_ Cambodia', 'NativeCountry_ Canada',\n",
      "       'NativeCountry_ China', 'NativeCountry_ Columbia',\n",
      "       'NativeCountry_ Cuba', 'NativeCountry_ Dominican_Republic',\n",
      "       'NativeCountry_ Ecuador', 'NativeCountry_ El_Salvador',\n",
      "       'NativeCountry_ England', 'NativeCountry_ France',\n",
      "       'NativeCountry_ Germany', 'NativeCountry_ Greece',\n",
      "       'NativeCountry_ Guatemala', 'NativeCountry_ Haiti',\n",
      "       'NativeCountry_ Holand_Netherlands', 'NativeCountry_ Honduras',\n",
      "       'NativeCountry_ Hong', 'NativeCountry_ Hungary', 'NativeCountry_ India',\n",
      "       'NativeCountry_ Iran', 'NativeCountry_ Ireland', 'NativeCountry_ Italy',\n",
      "       'NativeCountry_ Jamaica', 'NativeCountry_ Japan', 'NativeCountry_ Laos',\n",
      "       'NativeCountry_ Mexico', 'NativeCountry_ Nicaragua',\n",
      "       'NativeCountry_ Outlying_US(Guam_USVI_etc)', 'NativeCountry_ Peru',\n",
      "       'NativeCountry_ Philippines', 'NativeCountry_ Poland',\n",
      "       'NativeCountry_ Portugal', 'NativeCountry_ Puerto_Rico',\n",
      "       'NativeCountry_ Scotland', 'NativeCountry_ South',\n",
      "       'NativeCountry_ Taiwan', 'NativeCountry_ Thailand',\n",
      "       'NativeCountry_ Trinadad&Tobago', 'NativeCountry_ United_States',\n",
      "       'NativeCountry_ Vietnam', 'NativeCountry_ Yugoslavia'],\n",
      "      dtype='object')\n",
      "Index(['Age', 'EducationNum', 'CapitalGain', 'CapitalLoss', 'HoursPerWeek',\n",
      "       'WorkClass_ ?', 'WorkClass_ Federal-gov', 'WorkClass_ Local-gov',\n",
      "       'WorkClass_ Never-worked', 'WorkClass_ Private',\n",
      "       'WorkClass_ Self-emp-inc', 'WorkClass_ Self-emp-not-inc',\n",
      "       'WorkClass_ State-gov', 'WorkClass_ Without-pay',\n",
      "       'MaritalStatus_ Divorced', 'MaritalStatus_ Married-AF-spouse',\n",
      "       'MaritalStatus_ Married-civ-spouse',\n",
      "       'MaritalStatus_ Married-spouse-absent', 'MaritalStatus_ Never-married',\n",
      "       'MaritalStatus_ Separated', 'MaritalStatus_ Widowed', 'Occupation_ ?',\n",
      "       'Occupation_ Adm-clerical', 'Occupation_ Armed-Forces',\n",
      "       'Occupation_ Craft-repair', 'Occupation_ Exec-managerial',\n",
      "       'Occupation_ Farming-fishing', 'Occupation_ Handlers-cleaners',\n",
      "       'Occupation_ Machine-op-inspct', 'Occupation_ Other-service',\n",
      "       'Occupation_ Priv-house-serv', 'Occupation_ Prof-specialty',\n",
      "       'Occupation_ Protective-serv', 'Occupation_ Sales',\n",
      "       'Occupation_ Tech-support', 'Occupation_ Transport-moving',\n",
      "       'Relationship_ Husband', 'Relationship_ Not-in-family',\n",
      "       'Relationship_ Other-relative', 'Relationship_ Own-child',\n",
      "       'Relationship_ Unmarried', 'Relationship_ Wife',\n",
      "       'Race_ Amer-Indian-Eskimo', 'Race_ Asian-Pac-Islander', 'Race_ Black',\n",
      "       'Race_ Other', 'Race_ White', 'Gender_ Female', 'Gender_ Male',\n",
      "       'NativeCountry_ ?', 'NativeCountry_ Cambodia', 'NativeCountry_ Canada',\n",
      "       'NativeCountry_ China', 'NativeCountry_ Columbia',\n",
      "       'NativeCountry_ Cuba', 'NativeCountry_ Dominican-Republic',\n",
      "       'NativeCountry_ Ecuador', 'NativeCountry_ El-Salvador',\n",
      "       'NativeCountry_ England', 'NativeCountry_ France',\n",
      "       'NativeCountry_ Germany', 'NativeCountry_ Greece',\n",
      "       'NativeCountry_ Guatemala', 'NativeCountry_ Haiti',\n",
      "       'NativeCountry_ Honduras', 'NativeCountry_ Holand_Netherlands',\n",
      "       'NativeCountry_ Hong', 'NativeCountry_ Hungary', 'NativeCountry_ India',\n",
      "       'NativeCountry_ Iran', 'NativeCountry_ Ireland', 'NativeCountry_ Italy',\n",
      "       'NativeCountry_ Jamaica', 'NativeCountry_ Japan', 'NativeCountry_ Laos',\n",
      "       'NativeCountry_ Mexico', 'NativeCountry_ Nicaragua',\n",
      "       'NativeCountry_ Outlying-US(Guam-USVI-etc)', 'NativeCountry_ Peru',\n",
      "       'NativeCountry_ Philippines', 'NativeCountry_ Poland',\n",
      "       'NativeCountry_ Portugal', 'NativeCountry_ Puerto-Rico',\n",
      "       'NativeCountry_ Scotland', 'NativeCountry_ South',\n",
      "       'NativeCountry_ Taiwan', 'NativeCountry_ Thailand',\n",
      "       'NativeCountry_ Trinadad&Tobago', 'NativeCountry_ United-States',\n",
      "       'NativeCountry_ Vietnam', 'NativeCountry_ Yugoslavia'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.columns)\n",
    "print(Xte.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "contiCol = [\"Age\", \"EducationNum\", \"HoursPerWeek\",\"CapitalGain\",\"CapitalLoss\"]\n",
    "categCol = ['Age', 'WorkClass', 'EducationNum', 'MaritalStatus', 'Occupation',\n",
    "       'Relationship', 'Race', 'Gender', 'CapitalGain', 'CapitalLoss',\n",
    "       'HoursPerWeek', 'NativeCountry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "contiCol = [\"Age\", \"EducationNum\", \"HoursPerWeek\",\"CapitalGain\",\"CapitalLoss\"]\n",
    "categCol =['WorkClass_ ?', 'WorkClass_ Federal_gov', 'WorkClass_ Local_gov',\n",
    "       'WorkClass_ Never_worked', 'WorkClass_ Private',\n",
    "       'WorkClass_ Self_emp_inc', 'WorkClass_ Self_emp_not_inc',\n",
    "       'WorkClass_ State_gov', 'WorkClass_ Without_pay',\n",
    "       'MaritalStatus_ Divorced', 'MaritalStatus_ Married_AF_spouse',\n",
    "       'MaritalStatus_ Married_civ_spouse',\n",
    "       'MaritalStatus_ Married_spouse_absent', 'MaritalStatus_ Never_married',\n",
    "       'MaritalStatus_ Separated', 'MaritalStatus_ Widowed', 'Occupation_ ?',\n",
    "       'Occupation_ Adm_clerical', 'Occupation_ Armed_Forces',\n",
    "       'Occupation_ Craft_repair', 'Occupation_ Exec_managerial',\n",
    "       'Occupation_ Farming_fishing', 'Occupation_ Handlers_cleaners',\n",
    "       'Occupation_ Machine_op_inspct', 'Occupation_ Other_service',\n",
    "       'Occupation_ Priv_house_serv', 'Occupation_ Prof_specialty',\n",
    "       'Occupation_ Protective_serv', 'Occupation_ Sales',\n",
    "       'Occupation_ Tech_support', 'Occupation_ Transport_moving',\n",
    "       'Relationship_ Husband', 'Relationship_ Not_in_family',\n",
    "       'Relationship_ Other_relative', 'Relationship_ Own_child',\n",
    "       'Relationship_ Unmarried', 'Relationship_ Wife',\n",
    "       'Race_ Amer_Indian_Eskimo', 'Race_ Asian_Pac_Islander', 'Race_ Black',\n",
    "       'Race_ Other', 'Race_ White', 'Gender_ Female', 'Gender_ Male',\n",
    "       'NativeCountry_ ?', 'NativeCountry_ Cambodia', 'NativeCountry_ Canada',\n",
    "       'NativeCountry_ China', 'NativeCountry_ Columbia',\n",
    "       'NativeCountry_ Cuba', 'NativeCountry_ Dominican_Republic',\n",
    "       'NativeCountry_ Ecuador', 'NativeCountry_ El_Salvador',\n",
    "       'NativeCountry_ England', 'NativeCountry_ France',\n",
    "       'NativeCountry_ Germany', 'NativeCountry_ Greece',\n",
    "       'NativeCountry_ Guatemala', 'NativeCountry_ Haiti',\n",
    "       'NativeCountry_ Holand_Netherlands', 'NativeCountry_ Honduras',\n",
    "       'NativeCountry_ Hong', 'NativeCountry_ Hungary', 'NativeCountry_ India',\n",
    "       'NativeCountry_ Iran', 'NativeCountry_ Ireland', 'NativeCountry_ Italy',\n",
    "       'NativeCountry_ Jamaica', 'NativeCountry_ Japan', 'NativeCountry_ Laos',\n",
    "       'NativeCountry_ Mexico', 'NativeCountry_ Nicaragua',\n",
    "       'NativeCountry_ Outlying_US(Guam_USVI_etc)', 'NativeCountry_ Peru',\n",
    "       'NativeCountry_ Philippines', 'NativeCountry_ Poland',\n",
    "       'NativeCountry_ Portugal', 'NativeCountry_ Puerto_Rico',\n",
    "       'NativeCountry_ Scotland', 'NativeCountry_ South',\n",
    "       'NativeCountry_ Taiwan', 'NativeCountry_ Thailand',\n",
    "       'NativeCountry_ Trinadad&Tobago', 'NativeCountry_ United_States',\n",
    "       'NativeCountry_ Vietnam', 'NativeCountry_ Yugoslavia']\n",
    "\n",
    "categCol1 = ['WorkClass_ ?', 'WorkClass_ Federal-gov', 'WorkClass_ Local-gov',\n",
    "       'WorkClass_ Never-worked', 'WorkClass_ Private',\n",
    "       'WorkClass_ Self-emp-inc', 'WorkClass_ Self-emp-not-inc',\n",
    "       'WorkClass_ State-gov', 'WorkClass_ Without-pay',\n",
    "       'MaritalStatus_ Divorced', 'MaritalStatus_ Married-AF-spouse',\n",
    "       'MaritalStatus_ Married-civ-spouse',\n",
    "       'MaritalStatus_ Married-spouse-absent', 'MaritalStatus_ Never-married',\n",
    "       'MaritalStatus_ Separated', 'MaritalStatus_ Widowed', 'Occupation_ ?',\n",
    "       'Occupation_ Adm-clerical', 'Occupation_ Armed-Forces',\n",
    "       'Occupation_ Craft-repair', 'Occupation_ Exec-managerial',\n",
    "       'Occupation_ Farming-fishing', 'Occupation_ Handlers-cleaners',\n",
    "       'Occupation_ Machine-op-inspct', 'Occupation_ Other-service',\n",
    "       'Occupation_ Priv-house-serv', 'Occupation_ Prof-specialty',\n",
    "       'Occupation_ Protective-serv', 'Occupation_ Sales',\n",
    "       'Occupation_ Tech-support', 'Occupation_ Transport-moving',\n",
    "       'Relationship_ Husband', 'Relationship_ Not-in-family',\n",
    "       'Relationship_ Other-relative', 'Relationship_ Own-child',\n",
    "       'Relationship_ Unmarried', 'Relationship_ Wife',\n",
    "       'Race_ Amer-Indian-Eskimo', 'Race_ Asian-Pac-Islander', 'Race_ Black',\n",
    "       'Race_ Other', 'Race_ White', 'Gender_ Female', 'Gender_ Male',\n",
    "       'NativeCountry_ ?', 'NativeCountry_ Cambodia', 'NativeCountry_ Canada',\n",
    "       'NativeCountry_ China', 'NativeCountry_ Columbia',\n",
    "       'NativeCountry_ Cuba', 'NativeCountry_ Dominican-Republic',\n",
    "       'NativeCountry_ Ecuador', 'NativeCountry_ El-Salvador',\n",
    "       'NativeCountry_ England', 'NativeCountry_ France',\n",
    "       'NativeCountry_ Germany', 'NativeCountry_ Greece',\n",
    "       'NativeCountry_ Guatemala', 'NativeCountry_ Haiti',\n",
    "       'NativeCountry_ Honduras', 'NativeCountry_ Holand_Netherlands',\n",
    "       'NativeCountry_ Hong', 'NativeCountry_ Hungary', 'NativeCountry_ India',\n",
    "       'NativeCountry_ Iran', 'NativeCountry_ Ireland', 'NativeCountry_ Italy',\n",
    "       'NativeCountry_ Jamaica', 'NativeCountry_ Japan', 'NativeCountry_ Laos',\n",
    "       'NativeCountry_ Mexico', 'NativeCountry_ Nicaragua',\n",
    "       'NativeCountry_ Outlying-US(Guam-USVI-etc)', 'NativeCountry_ Peru',\n",
    "       'NativeCountry_ Philippines', 'NativeCountry_ Poland',\n",
    "       'NativeCountry_ Portugal', 'NativeCountry_ Puerto-Rico',\n",
    "       'NativeCountry_ Scotland', 'NativeCountry_ South',\n",
    "       'NativeCountry_ Taiwan', 'NativeCountry_ Thailand',\n",
    "       'NativeCountry_ Trinadad&Tobago', 'NativeCountry_ United-States',\n",
    "       'NativeCountry_ Vietnam', 'NativeCountry_ Yugoslavia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>WorkClass_ ?</th>\n",
       "      <th>WorkClass_ Federal_gov</th>\n",
       "      <th>WorkClass_ Local_gov</th>\n",
       "      <th>WorkClass_ Never_worked</th>\n",
       "      <th>WorkClass_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>NativeCountry_ Portugal</th>\n",
       "      <th>NativeCountry_ Puerto_Rico</th>\n",
       "      <th>NativeCountry_ Scotland</th>\n",
       "      <th>NativeCountry_ South</th>\n",
       "      <th>NativeCountry_ Taiwan</th>\n",
       "      <th>NativeCountry_ Thailand</th>\n",
       "      <th>NativeCountry_ Trinadad&amp;Tobago</th>\n",
       "      <th>NativeCountry_ United_States</th>\n",
       "      <th>NativeCountry_ Vietnam</th>\n",
       "      <th>NativeCountry_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>62.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17049</th>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21016</th>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>64.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  EducationNum  CapitalGain  CapitalLoss  HoursPerWeek  \\\n",
       "24337  62.0           9.0            0            0          40.0   \n",
       "17049  50.0           9.0            0            0          40.0   \n",
       "21016  36.0           9.0            0            0          50.0   \n",
       "2790   64.0          10.0            0            0          40.0   \n",
       "13511  28.0          11.0            0            0          60.0   \n",
       "\n",
       "       WorkClass_ ?  WorkClass_ Federal_gov  WorkClass_ Local_gov  \\\n",
       "24337             0                       0                     1   \n",
       "17049             0                       0                     0   \n",
       "21016             0                       0                     0   \n",
       "2790              0                       0                     0   \n",
       "13511             0                       0                     0   \n",
       "\n",
       "       WorkClass_ Never_worked  WorkClass_ Private            ...              \\\n",
       "24337                        0                   0            ...               \n",
       "17049                        0                   1            ...               \n",
       "21016                        0                   1            ...               \n",
       "2790                         0                   1            ...               \n",
       "13511                        0                   0            ...               \n",
       "\n",
       "       NativeCountry_ Portugal  NativeCountry_ Puerto_Rico  \\\n",
       "24337                        0                           0   \n",
       "17049                        0                           0   \n",
       "21016                        0                           0   \n",
       "2790                         0                           0   \n",
       "13511                        0                           0   \n",
       "\n",
       "       NativeCountry_ Scotland  NativeCountry_ South  NativeCountry_ Taiwan  \\\n",
       "24337                        0                     0                      0   \n",
       "17049                        0                     0                      0   \n",
       "21016                        0                     0                      0   \n",
       "2790                         0                     0                      0   \n",
       "13511                        0                     0                      0   \n",
       "\n",
       "       NativeCountry_ Thailand  NativeCountry_ Trinadad&Tobago  \\\n",
       "24337                        0                               0   \n",
       "17049                        0                               0   \n",
       "21016                        0                               0   \n",
       "2790                         0                               0   \n",
       "13511                        0                               0   \n",
       "\n",
       "       NativeCountry_ United_States  NativeCountry_ Vietnam  \\\n",
       "24337                             1                       0   \n",
       "17049                             1                       0   \n",
       "21016                             1                       0   \n",
       "2790                              0                       0   \n",
       "13511                             1                       0   \n",
       "\n",
       "       NativeCountry_ Yugoslavia  \n",
       "24337                          0  \n",
       "17049                          0  \n",
       "21016                          0  \n",
       "2790                           0  \n",
       "13511                          0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# df1 = df[['a','b']]\n",
    "def standardization(X):\n",
    "    Xscaler = X[contiCol]\n",
    "    array = Xscaler.values\n",
    "    scaler = StandardScaler().fit(Xscaler)\n",
    "    rescaledX = scaler.transform(Xscaler)\n",
    "    return rescaledX  \n",
    "\n",
    "Xtr_scaled = standardization(Xtr)\n",
    "Xtr.Age = Xtr_scaled[:,0]\n",
    "# Xtr.FnlWgt = Xtr_scaled[:,1]\n",
    "Xtr.EducationNum = Xtr_scaled[:,1]\n",
    "Xtr.HoursPerWeek = Xtr_scaled[:,2]\n",
    "Xtr.CapitalGain = Xtr_scaled[:,3]\n",
    "Xtr.CapitalLoss = Xtr_scaled[:,4]\n",
    "\n",
    "Xva_scaled = standardization(Xva)\n",
    "Xva.Age = Xva_scaled[:,0]\n",
    "# Xva.FnlWgt = Xva_scaled[:,1]\n",
    "Xva.EducationNum = Xva_scaled[:,1]\n",
    "Xva.HoursPerWeek = Xva_scaled[:,2]\n",
    "Xva.CapitalGain= Xva_scaled[:,3]\n",
    "Xva.CapitalLoss= Xva_scaled[:,4]\n",
    "\n",
    "\n",
    "Xte_scaled = standardization(Xte)\n",
    "Xte.Age = Xte_scaled[:,0]\n",
    "# Xte.FnlWgt = Xte_scaled[:,1]\n",
    "Xte.EducationNum = Xte_scaled[:,1]\n",
    "Xte.HoursPerWeek = Xte_scaled[:,2]\n",
    "Xte.CapitalGain= Xte_scaled[:,3]\n",
    "Xte.CapitalLoss= Xte_scaled[:,4]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "def normalization(X):\n",
    "    Xnormal = X.filter([\"CapitalGain\",\"CapitalLoss\"],axis=1)\n",
    "    scaler = Normalizer().fit(Xnormal)\n",
    "    normalizedX = scaler.transform(Xnormal)\n",
    "    return normalizedX\n",
    "\n",
    "Xtr_normal = normalization(Xtr)\n",
    "Xtr.CapitalGain = Xtr_normal[:,0]\n",
    "Xtr.CapitalLoss = Xtr_normal[:,1]\n",
    "\n",
    "Xva_normal = normalization(Xva)\n",
    "Xva.CapitalGain= Xva_normal[:,0]\n",
    "Xva.CapitalLoss= Xva_normal[:,1]\n",
    "\n",
    "Xte_normal = normalization(Xte)\n",
    "Xte.CapitalGain= Xte_normal[:,0]\n",
    "Xte.CapitalLoss= Xte_normal[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xtr.drop('CapitalGain',axis=1,inplace=True)\n",
    "Xva.drop('CapitalGain',axis=1,inplace=True)\n",
    "Xte.drop('CapitalGain',axis=1,inplace=True)\n",
    "Xtr.drop('CapitalLoss',axis=1,inplace=True)\n",
    "Xva.drop('CapitalLoss',axis=1,inplace=True)\n",
    "Xte.drop('CapitalLoss',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for training data 0.7632802889071495\n",
      "Acuracy for training data 0.8509400729119732\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(Xtr, Ytr)\n",
    "Ytrhat = clf.predict(Xtr)\n",
    "auc_tr = roc_auc_score(Ytr, Ytrhat)\n",
    "accuracy_tr = clf.score(Xtr, Ytr)\n",
    "print(f\"AUC for training data {auc_tr}\")\n",
    "print(f\"Acuracy for training data {accuracy_tr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for validation data 0.7736834459647698\n",
      "Acuracy for validation data 0.8565292096219931\n"
     ]
    }
   ],
   "source": [
    "Yvahat = clf.predict(Xva)\n",
    "auc_val = roc_auc_score(Yva, Yvahat)\n",
    "accuracy_val = clf.score(Xva, Yva)\n",
    "print(f\"AUC for validation data {auc_val}\")\n",
    "print(f\"Acuracy for validation data {accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test data 0.7634631440746171\n",
      "Acuracy for test data 0.8519746944290891\n"
     ]
    }
   ],
   "source": [
    "Ytehat = clf.predict(Xte)\n",
    "auc_test = roc_auc_score(Yte, Ytehat)\n",
    "accuracy_test = clf.score(Xte, Yte)\n",
    "print(f\"AUC for test data {auc_test}\")\n",
    "print(f\"Acuracy for test data {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for training data 0.63012424107179\n",
      "Acuracy for training data 0.7962151312825134\n"
     ]
    }
   ],
   "source": [
    "#Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(Xtr[contiCol], Ytr)\n",
    "\n",
    "YtrhatGNB = gnb.predict(Xtr[contiCol])\n",
    "auc_tr_gnb = roc_auc_score(Ytr, YtrhatGNB)\n",
    "accuracy_tr_gnb = gnb.score(Xtr[contiCol], Ytr)\n",
    "print(f\"AUC for training data {auc_tr_gnb}\")\n",
    "print(f\"Acuracy for training data {accuracy_tr_gnb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for validation data 0.6275590817552993\n",
      "Acuracy for validation data 0.7986008836524301\n"
     ]
    }
   ],
   "source": [
    "YvahatGNB = gnb.predict(Xva[contiCol])\n",
    "auc_va_gnb = roc_auc_score(Yva, YvahatGNB)\n",
    "accuracy_va_gnb = gnb.score(Xva[contiCol], Yva)\n",
    "print(f\"AUC for validation data {auc_va_gnb}\")\n",
    "print(f\"Acuracy for validation data {accuracy_va_gnb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test data 0.6248953215064671\n",
      "Acuracy for test data 0.796265585651987\n"
     ]
    }
   ],
   "source": [
    "YtehatGNB = gnb.predict(Xte[contiCol])\n",
    "auc_te_gnb = roc_auc_score(Yte, YtehatGNB)\n",
    "accuracy_te_gnb = gnb.score(Xte[contiCol], Yte)\n",
    "print(f\"AUC for test data {auc_te_gnb}\")\n",
    "print(f\"Acuracy for test data {accuracy_te_gnb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yvahat1=pd.DataFrame(YvahatGNB)\n",
    "Ytehat1=pd.DataFrame(YtehatGNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for training data 0.7632765156281706\n",
      "Acuracy for training data 0.7620530045467578\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(Xtr[categCol], Ytr)\n",
    "YtrhatMNB = mnb.predict(Xtr[categCol])\n",
    "auc_tr_mnb = roc_auc_score(Ytr, YtrhatMNB)\n",
    "accuracy_tr_mnb = mnb.score(Xtr[categCol], Ytr)\n",
    "print(f\"AUC for training data {auc_tr_mnb}\")\n",
    "print(f\"Acuracy for training data {accuracy_tr_mnb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for validation data 0.7656534812267674\n",
      "Acuracy for validation data 0.7622729504172803\n"
     ]
    }
   ],
   "source": [
    "YvahatMNB = mnb.predict(Xva[categCol])\n",
    "auc_va_mnb = roc_auc_score(Yva, YvahatMNB)\n",
    "accuracy_va_mnb = mnb.score(Xva[categCol], Yva)\n",
    "print(f\"AUC for validation data {auc_va_mnb}\")\n",
    "print(f\"Acuracy for validation data {accuracy_va_mnb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test data 0.7673673460810567\n",
      "Acuracy for test data 0.7667219458264234\n"
     ]
    }
   ],
   "source": [
    "YtehatMNB = mnb.predict(Xte[categCol1])\n",
    "auc_test_mnb = roc_auc_score(Yte, YtehatMNB)\n",
    "accuracy_test_mnb = mnb.score(Xte[categCol1], Yte)\n",
    "print(f\"AUC for test data {auc_test_mnb}\")\n",
    "print(f\"Acuracy for test data {accuracy_test_mnb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yvahat2=pd.DataFrame(YvahatMNB)\n",
    "Ytehat2=pd.DataFrame(YtehatMNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva.reset_index(drop=True, inplace=True)\n",
    "Yvahat1.reset_index(drop=True, inplace=True)\n",
    "Yvahat2.reset_index(drop=True, inplace=True)\n",
    "Xte.reset_index(drop=True, inplace=True)\n",
    "Ytehat1.reset_index(drop=True, inplace=True)\n",
    "Ytehat2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test data 0.7659694686943087\n",
      "Acuracy for test data 0.8544315459738345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_val=pd.concat([Xva, Yvahat1,Yvahat2],axis=1)\n",
    "df_test=pd.concat([Xte, Ytehat1,Ytehat2],axis=1)\n",
    "# print(df_val,df_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(df_val,Yva)\n",
    "Ytehaten = model.predict(df_test)\n",
    "accuracy_test_ensemble = model.score(df_test,Yte)\n",
    "auc_test_ensemble = roc_auc_score(Yte,Ytehaten)\n",
    "print(f\"AUC for test data {auc_test_ensemble}\")\n",
    "print(f\"Acuracy for test data {accuracy_test_ensemble}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24413, 91)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import mltools as ml\n",
    "\n",
    "layerList = [Xtr[contiCol].shape[1],len(np.unique(Ytr))]\n",
    "layers = [1, 4, 7]\n",
    "nodes = [2,5,8]\n",
    "tr_auc_nn = np.zeros((len(layers),len(nodes)))\n",
    "va_auc_nn = np.zeros((len(layers),len(nodes)))\n",
    "\n",
    "for i,k in enumerate(layers):\n",
    "    print(f'layer {k}:')\n",
    "    for j,n in enumerate(nodes):\n",
    "        layerList = [Xtr[contiCol].shape[1],len(np.unique(Ytr))]\n",
    "        for a in range(k):\n",
    "            layerList.insert(1,n)\n",
    "        nn = ml.nnet.nnetClassify()\n",
    "        nn.init_weights(layerList, 'random', Xtr[contiCol], Ytr) # as many layers nodes you want\n",
    "        print(layerList)\n",
    "        \n",
    "#         nn.train(Xtr[contiCol], Ytr, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "#         tr_auc_nn[i][j] = nn.auc(Xtr, Ytr)\n",
    "#         va_auc_nn[i][j] = nn.auc(Xva, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for training data for neural networks  0.5\n",
      "Acuracy for training data for neural networks 0.7584483676729611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "mlp.fit(Xtr, Ytr)  \n",
    "YtrhatNN = mlp.predict(Xtr)\n",
    "auc_tr_nn= roc_auc_score(Ytr, YtrhatNN)\n",
    "accuracy_tr_nn = mlp.score(Xtr, Ytr)\n",
    "print(f\"AUC for training data for neural networks  {auc_tr_nn}\")\n",
    "print(f\"Acuracy for training data for neural networks {accuracy_tr_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for validation data for neural networks  0.5\n",
      "Acuracy for validation data for neural networks 0.7614138438880707\n"
     ]
    }
   ],
   "source": [
    "YvahatNN = mlp.predict(Xva)\n",
    "auc_va_nn= roc_auc_score(Yva, YvahatNN)\n",
    "accuracy_va_nn = mlp.score(Xva, Yva)\n",
    "print(f\"AUC for validation data for neural networks  {auc_va_nn}\")\n",
    "print(f\"Acuracy for validation data for neural networks {accuracy_va_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test data for neural networks  0.5\n",
      "Acuracy for test data for neural networks 0.7637737239727289\n"
     ]
    }
   ],
   "source": [
    "YtehatNN = mlp.predict(Xte)\n",
    "auc_te_nn= roc_auc_score(Yte, YtehatNN)\n",
    "accuracy_te_nn = mlp.score(Xte, Yte)\n",
    "print(f\"AUC for test data for neural networks  {auc_te_nn}\")\n",
    "print(f\"Acuracy for test data for neural networks {accuracy_te_nn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
