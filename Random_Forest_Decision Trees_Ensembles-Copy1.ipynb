{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "from data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# so that same output is produced\n",
    "\n",
    "def load_train_data(train_file_path, valid_rate=0.1, is_df=True):\n",
    "    data_frame = pd.read_csv(train_file_path, header=None).sample(frac=1, random_state=11)\n",
    "    np.random.seed(11)\n",
    "    mask = np.random.rand(len(data_frame)) < 1 - valid_rate\n",
    "    print(mask)\n",
    "    train_df, valid_df = data_frame.iloc[mask, :], data_frame.iloc[~mask, :]\n",
    "    if is_df:\n",
    "        return train_df, valid_df\n",
    "\n",
    "    train_labels = [1 if x == POS_STR else 0 for x in train_df.iloc[:, 14].values]\n",
    "    valid_labels = [1 if x == POS_STR else 0 for x in valid_df.iloc[:, 14].values]\n",
    "    return train_df.iloc[:, :14].values, np.array(train_labels), valid_df.iloc[:, :14].values, np.array(valid_labels)\n",
    "\n",
    "rs = RandomState(130917)\n",
    "numpy.random.seed()\n",
    "Xtr,Xva = load_train_data(\"adult_data.csv\")\n",
    "Xte = load_test_data(\"adult_test.csv\")\n",
    "\n",
    "# give names to columns\n",
    "Xtr.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "Xva.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "Xte.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.drop(\"Education\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva.drop(\"Education\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.drop(\"Education\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.drop(\"fnlwgt\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva.drop(\"fnlwgt\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.drop(\"fnlwgt\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert income to 0 and 1\n",
    "Xtr[\"Income\"] = Xtr[\"Income\"].map({ \" <=50K\": 0, \" >50K\": 1 })\n",
    "Ytr = Xtr[\"Income\"].values\n",
    "Xtr.drop(\"Income\", axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva[\"Income\"] = Xva[\"Income\"].map({ \" <=50K\": 0, \" >50K\": 1 })\n",
    "Yva = Xva[\"Income\"].values\n",
    "Xva.drop(\"Income\", axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte[\"Income\"] = Xte[\"Income\"].map({ \" <=50K.\": 0, \" >50K.\": 1 })\n",
    "Yte = Xte[\"Income\"].values\n",
    "Xte.drop(\"Income\", axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = pd.get_dummies(Xtr, columns=[\n",
    "    \"WorkClass\", \"MaritalStatus\", \"Occupation\", \"Relationship\",\n",
    "    \"Race\", \"Gender\", \"NativeCountry\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva = pd.get_dummies(Xva, columns=[\n",
    "    \"WorkClass\", \"MaritalStatus\", \"Occupation\", \"Relationship\",\n",
    "    \"Race\", \"Gender\", \"NativeCountry\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte = pd.get_dummies(Xte, columns=[\n",
    "    \"WorkClass\", \"MaritalStatus\", \"Occupation\", \"Relationship\",\n",
    "    \"Race\", \"Gender\", \"NativeCountry\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.insert(loc=65, column='NativeCountry_ Holand-Netherlands', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xva.insert(loc=66, column='WorkClass_ Never-worked', value=0)\n",
    "Xva.insert(loc=67, column='NativeCountry_ Cambodia', value=0)\n",
    "Xva.insert(loc=68, column='NativeCountry_ Honduras', value=0)\n",
    "Xva.insert(loc=69, column='NativeCountry_ Hungary', value=0)\n",
    "Xva.insert(loc=70, column='NativeCountry_ Scotland', value=0)\n",
    "Xva.insert(loc=71, column='NativeCountry_ Trinadad&Tobago', value=0)\n",
    "Xva.insert(loc=65, column='NativeCountry_ Holand-Netherlands', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.Age = Xtr.Age.astype(float)\n",
    "Xtr.EducationNum = Xtr.EducationNum.astype(float)\n",
    "Xtr.HoursPerWeek = Xtr.HoursPerWeek.astype(float)\n",
    "\n",
    "Xva.Age = Xva.Age.astype(float)\n",
    "Xva.EducationNum = Xva.EducationNum.astype(float)\n",
    "Xva.HoursPerWeek = Xva.HoursPerWeek.astype(float)\n",
    "\n",
    "Xte.Age = Xte.Age.astype(float)\n",
    "Xte.EducationNum = Xte.EducationNum.astype(float)\n",
    "Xte.HoursPerWeek = Xte.HoursPerWeek.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "# also try without standardizing the results\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "def standardization(X):\n",
    "    \n",
    "    Xscaler = X.filter([\"Age\", \"EducationNum\", \"HoursPerWeek\", \"CapitalGain\",\"CapitalLoss\"],axis=1)\n",
    "    array = Xscaler.values\n",
    "    scaler = StandardScaler().fit(Xscaler)\n",
    "    rescaledX = scaler.transform(Xscaler)\n",
    "    return rescaledX\n",
    "\n",
    "Xtr_scaled = standardization(Xtr)\n",
    "Xtr.Age = Xtr_scaled[:,0]\n",
    "Xtr.EducationNum = Xtr_scaled[:,1]\n",
    "Xtr.HoursPerWeek = Xtr_scaled[:,2]\n",
    "Xtr.CapitalGain = Xtr_scaled[:,3]\n",
    "Xtr.CapitalLoss = Xtr_scaled[:,4]\n",
    "\n",
    "\n",
    "Xva_scaled = standardization(Xva)\n",
    "Xva.Age = Xva_scaled[:,0]\n",
    "Xva.EducationNum = Xva_scaled[:,1]\n",
    "Xva.HoursPerWeek = Xva_scaled[:,2]\n",
    "Xva.CapitalGain = Xva_scaled[:,3]\n",
    "Xva.CapitalLoss = Xva_scaled[:,4]\n",
    "\n",
    "Xte_scaled = standardization(Xte)\n",
    "Xte.Age = Xte_scaled[:,0]\n",
    "Xte.EducationNum = Xte_scaled[:,1]\n",
    "Xte.HoursPerWeek = Xte_scaled[:,2]\n",
    "Xte.CapitalGain = Xte_scaled[:,3]\n",
    "Xte.CapitalLoss = Xte_scaled[:,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # also try without normalizing the results\n",
    "# def normalization(X):\n",
    "#     Xnormal = X.filter([\"CapitalGain\",\"CapitalLoss\"],axis=1)\n",
    "#     scaler = Normalizer().fit(Xnormal)\n",
    "#     normalizedX = scaler.transform(Xnormal)\n",
    "#     return normalizedX\n",
    "\n",
    "# Xtr_normal = normalization(Xtr)\n",
    "# Xtr.CapitalGain = Xtr_normal[:,0]\n",
    "# Xtr.CapitalLoss = Xtr_normal[:,1]\n",
    "\n",
    "# Xva_normal = normalization(Xva)\n",
    "# Xva.CapitalGain= Xva_normal[:,0]\n",
    "# Xva.CapitalLoss= Xva_normal[:,1]\n",
    "\n",
    "# Xte_normal = normalization(Xte)\n",
    "# Xte.CapitalGain= Xte_normal[:,0]\n",
    "# Xte.CapitalLoss= Xte_normal[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation\n",
      "0.8043746149106593\n",
      "For test\n",
      "0.8469381487623611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "# kfold = model_selection.KFold(n_splits=5,random_state=7)\n",
    "randomForest = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "# cv_result = model_selection.cross_val_score(randomForest,Xtr,Ytr,cv=kfold,scoring='accuracy')\n",
    "score=randomForest.fit(Xtr,Ytr)\n",
    "# YvaHat=score.predict(Xva)\n",
    "# acc_score=roc_auc_score(Yva, YvaHat)\n",
    "# YteHat = score.predict(Xte)\n",
    "# acc_score1=roc_auc_score(Yte, YteHat)\n",
    "prediction = randomForest.predict(Xva)\n",
    "acc_score = accuracy_score(Yva,prediction)\n",
    "prediction1 = randomForest.predict(Xte)\n",
    "acc_score1 = accuracy_score(Yte,prediction1)\n",
    "print(\"For validation\")\n",
    "print(acc_score)\n",
    "print(\"For test\")\n",
    "print(acc_score1)\n",
    "# print(\"For test\")\n",
    "# print(acc_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8105360443622921\n",
      "For validation\n",
      "0.6070226324702706\n",
      "For test\n",
      "0.7768107732753218\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_leaf_nodes': 60, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "decisionTree = DecisionTreeClassifier(random_state=43)\n",
    "criterion = [\"gini\",\"entropy\"]\n",
    "max_depth = [1,3,5,None]\n",
    "splitter = [\"best\",\"random\"]\n",
    "max_leaf_nodes = [20,40,60]\n",
    "grid = GridSearchCV(estimator=decisionTree,cv=3,param_grid=dict(criterion=criterion,max_depth=max_depth,splitter=splitter,max_leaf_nodes=max_leaf_nodes))\n",
    "YvaHat=grid.fit(Xtr,Ytr).predict(Xva)\n",
    "# kfold = model_selection.KFold(n_splits=5,random_state=7)\n",
    "# cv_result = model_selection.cross_val_score(decisionTree,Xtr,Ytr,cv=kfold,scoring='accuracy')\n",
    "# score=decisionTree.fit(Xtr,Ytr)\n",
    "# YvaHat=score.predict(Xva)\n",
    "acc_score=accuracy_score(Yva,YvaHat)\n",
    "print(acc_score)\n",
    "# acc_score=roc_auc_score(Yva, YvaHat)\n",
    "YteHat = grid.fit(Xtr,Ytr).predict(Xte)\n",
    "# acc_score1=roc_auc_score(Yte, YteHat)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(Yva, YvaHat)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "false_positive_rate1, true_positive_rate1, thresholds1 = roc_curve(Yte, YteHat)\n",
    "roc_auc1 = auc(false_positive_rate1, true_positive_rate1)\n",
    "print(\"For validation\")\n",
    "print(roc_auc)\n",
    "print(\"For test\")\n",
    "print(roc_auc1)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy\n",
      "0.7674060382008626\n",
      "Test accuracy\n",
      "0.8576868742706222\n",
      "Validation auc\n",
      "0.5\n",
      "test auc\n",
      "0.5628823078134223\n",
      "Validation accuracy\n",
      "0.7766481823783118\n",
      "Test accuracy\n",
      "0.8576868742706222\n",
      "Validation auc\n",
      "0.5203290787231384\n",
      "test auc\n",
      "0.6613268246049504\n",
      "Validation accuracy\n",
      "0.7957486136783734\n",
      "Test accuracy\n",
      "0.8576868742706222\n",
      "Validation auc\n",
      "0.5618502104264091\n",
      "test auc\n",
      "0.7407957259183009\n",
      "Validation accuracy\n",
      "0.7960566851509551\n",
      "Test accuracy\n",
      "0.8576868742706222\n",
      "Validation auc\n",
      "0.5643585782990953\n",
      "test auc\n",
      "0.7622248798275212\n",
      "Validation accuracy\n",
      "0.7658656808379544\n",
      "Test accuracy\n",
      "0.8576868742706222\n",
      "Validation auc\n",
      "0.7186842168229468\n",
      "test auc\n",
      "0.7701979780035592\n",
      "Validation accuracy\n",
      "0.8219346888478127\n",
      "Test accuracy\n",
      "0.8576868742706222\n",
      "Validation auc\n",
      "0.7053705924108247\n",
      "test auc\n",
      "0.7681686423066091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score\n",
    "\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=3, max_depth = 6, random_state = 0)\n",
    "    gb.fit(Xtr,Ytr)\n",
    "    prediction = gb.predict(Xva)\n",
    "    acc_score = accuracy_score(Yva,prediction)\n",
    "    roc=roc_auc_score(Yva,prediction)\n",
    "       \n",
    "    prediction1=gb.predict(Xte)\n",
    "    acc_score1=accuracy_score(Yte, YteHat)\n",
    "    roc1=roc_auc_score(Yte,prediction1)\n",
    "    \n",
    "    print(\"Validation accuracy\")\n",
    "    print(acc_score)\n",
    "    print(\"Test accuracy\")\n",
    "    print(acc_score1)\n",
    "    print(\"Validation auc\")\n",
    "    print(roc)\n",
    "    print(\"test auc\")\n",
    "    print(roc1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy\n",
      "0.8213185459026494\n",
      "Test accuracy\n",
      "0.8576868742706222\n",
      "Validation auc\n",
      "0.6694314100297495\n",
      "test auc\n",
      "0.7670792645939853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10,leaf_size=6)\n",
    "\n",
    "knn.fit(Xtr,Ytr)\n",
    "\n",
    "prediction = knn.predict(Xva)\n",
    "acc_score = accuracy_score(Yva,prediction)\n",
    "roc=roc_auc_score(Yva,prediction)\n",
    "\n",
    "prediction1=knn.predict(Xte)\n",
    "acc_score1=accuracy_score(Yte, YteHat)\n",
    "roc1=roc_auc_score(Yte,prediction1)\n",
    "    \n",
    "print(\"Validation accuracy\")\n",
    "print(acc_score)\n",
    "print(\"Test accuracy\")\n",
    "print(acc_score1)\n",
    "print(\"Validation auc\")\n",
    "print(roc)\n",
    "print(\"test auc\")\n",
    "print(roc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salonikhasgiwala/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy\n",
      "0.8179297597042514\n",
      "Test accuracy\n",
      "0.8576868742706222\n",
      "Validation auc\n",
      "0.6303011370735974\n",
      "test auc\n",
      "0.72711061639088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salonikhasgiwala/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "model1 = RandomForestClassifier(random_state=1,max_depth=4,max_features=3)\n",
    "model2 = LogisticRegression(random_state=5)\n",
    "model3 = KNeighborsClassifier(n_neighbors=6)\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2), ('kn',model3)], voting='hard')\n",
    "model.fit(Xtr,Ytr)\n",
    "\n",
    "prediction = model.predict(Xva)\n",
    "acc_score = accuracy_score(Yva,prediction)\n",
    "roc=roc_auc_score(Yva,prediction)\n",
    "\n",
    "prediction1=model.predict(Xte)\n",
    "acc_score1=accuracy_score(Yte, YteHat)\n",
    "roc1=roc_auc_score(Yte,prediction1)\n",
    "    \n",
    "print(\"Validation accuracy\")\n",
    "print(acc_score)\n",
    "print(\"Test accuracy\")\n",
    "print(acc_score1)\n",
    "print(\"Validation auc\")\n",
    "print(roc)\n",
    "print(\"test auc\")\n",
    "print(roc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-970-f7ee40f72a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfinalpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpred2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpred3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYva\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinalpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mroc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYva\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinalpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(Xtr,Ytr)\n",
    "model2.fit(Xtr,Ytr)\n",
    "model3.fit(Xtr,Ytr)\n",
    "\n",
    "pred1=model1.predict_proba(Xva)\n",
    "pred2=model2.predict_proba(Xva)\n",
    "pred3=model3.predict_proba(Xva)\n",
    "\n",
    "finalpred=(pred1+pred2+pred3)/3\n",
    "acc_score = accuracy_score(Yva,finalpred)\n",
    "roc=roc_auc_score(Yva,finalpred)\n",
    "\n",
    "pred4=model1.predict_proba(Xte)\n",
    "pred5=model2.predict_proba(Xte)\n",
    "pred6=model3.predict_proba(Xte)\n",
    "\n",
    "finalpred1=(pred4+pred5+pred6)/3\n",
    "acc_score = accuracy_score(Yte,finalpred1)\n",
    "roc=roc_auc_score(Yte,finalpred1)\n",
    "    \n",
    "print(\"Validation accuracy\")\n",
    "print(acc_score)\n",
    "print(\"Test accuracy\")\n",
    "print(acc_score1)\n",
    "print(\"Validation auc\")\n",
    "print(roc)\n",
    "print(\"test auc\")\n",
    "print(roc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [>50K] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [>50K] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1003-52f470b890da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0msvm_clf_rbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0msvm_clf_rbf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_clf_rbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mSVM_rbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_clf_rbf_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM using rbf kernel : %.2f percent.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVM_rbf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1003-52f470b890da>\u001b[0m in \u001b[0;36mmodel_eval\u001b[0;34m(actual, pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mTP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'>50K'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'>50K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mTN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<=50K'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<=50K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mFP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<=50K'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'>50K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                 \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [>50K] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "# rbf kernal\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "def model_eval(actual, pred):\n",
    "    \n",
    "    confusion = pd.crosstab(actual, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    TP = confusion.loc['>50K','>50K']\n",
    "    TN = confusion.loc['<=50K','<=50K']\n",
    "    FP = confusion.loc['<=50K','>50K']\n",
    "    FN = confusion.loc['>50K','<=50K']\n",
    "\n",
    "    accuracy = ((TP+TN))/(TP+FN+FP+TN)\n",
    "    precision = (TP)/(TP+FP)\n",
    "    recall = (TP)/(TP+FN)\n",
    "    f_measure = (2*recall*precision)/(recall+precision)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    error_rate = 1 - accuracy\n",
    "    \n",
    "    out = {}\n",
    "    out['accuracy'] =  accuracy\n",
    "    out['precision'] = precision\n",
    "    out['recall'] = recall\n",
    "    out['f_measure'] = f_measure\n",
    "    out['sensitivity'] = sensitivity\n",
    "    out['specificity'] = specificity\n",
    "    out['error_rate'] = error_rate\n",
    "    \n",
    "    return out\n",
    "\n",
    "svm_clf_rbf = svm.SVC(kernel = 'rbf', C = 1, tol = 1e-3)\n",
    "svm_clf_rbf.fit(Xtr, Ytr)\n",
    "svm_clf_rbf_pred = svm_clf_rbf.predict(Xte)\n",
    "SVM_rbf = model_eval(Yte, svm_clf_rbf_pred)\n",
    "print('SVM using rbf kernel : %.2f percent.' % (round(SVM_rbf['accuracy']*100,2)))\n",
    "\n",
    "# Linear kernel\n",
    "svm_clf_linear = svm.SVC(kernel = 'linear')\n",
    "svm_clf_linear.fit(Xtr, Ytr)\n",
    "svm_clf_linear_pred = svm_clf_linear.predict(Xte)\n",
    "SVM_linear = model_eval(Yte, svm_clf_linear_pred)\n",
    "print('SVM using linear kernel : %.2f percent.' % (round(SVM_linear['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "# Poly kernal\n",
    "svm_clf_poly = svm.SVC(kernel = 'poly')\n",
    "svm_clf_poly.fit(Xtr, Ytr)\n",
    "svm_clf_poly_pred = svm_clf_poly.predict(Xte)\n",
    "SVM_poly = model_eval(Yte, svm_clf_poly_pred)\n",
    "print('SVM using poly kernel : %.2f percent.' % (round(SVM_poly['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "svm_clf_sigmoid = svm.SVC(kernel = 'sigmoid')\n",
    "svm_clf_sigmoid.fit(Xtr, Ytr)\n",
    "svm_clf_sigmoid_pred = svm_clf_sigmoid.predict(Xte)\n",
    "SVM_sigmoid = model_eval(Yte, svm_clf_sigmoid_pred)\n",
    "print('SVM using sigmoid kernel : %.2f percent.' % (round(SVM_sigmoid['accuracy']*100,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
