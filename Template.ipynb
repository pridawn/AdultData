{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "from data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so that same output is produced\n",
    "rs = RandomState(130917)\n",
    "\n",
    "Xtr,Xva = load_train_data(\"adult_data.csv\")\n",
    "Xte = load_test_data(\"adult_test.csv\")\n",
    "\n",
    "# give names to columns\n",
    "Xtr.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "Xva.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "Xte.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.drop(\"Education\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva.drop(\"Education\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.drop(\"Education\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.drop(\"fnlwgt\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva.drop(\"fnlwgt\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.drop(\"fnlwgt\",axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert income to 0 and 1\n",
    "Xtr[\"Income\"] = Xtr[\"Income\"].map({ \" <=50K\": 0, \" >50K\": 1 })\n",
    "Ytr = Xtr[\"Income\"].values\n",
    "Xtr.drop(\"Income\", axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva[\"Income\"] = Xva[\"Income\"].map({ \" <=50K\": 0, \" >50K\": 1 })\n",
    "Yva = Xva[\"Income\"].values\n",
    "Xva.drop(\"Income\", axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte[\"Income\"] = Xte[\"Income\"].map({ \" <=50K.\": 0, \" >50K.\": 1 })\n",
    "Yte = Xte[\"Income\"].values\n",
    "Xte.drop(\"Income\", axis=1, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = pd.get_dummies(Xtr, columns=[\n",
    "    \"WorkClass\", \"MaritalStatus\", \"Occupation\", \"Relationship\",\n",
    "    \"Race\", \"Gender\", \"NativeCountry\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xva = pd.get_dummies(Xva, columns=[\n",
    "    \"WorkClass\", \"MaritalStatus\", \"Occupation\", \"Relationship\",\n",
    "    \"Race\", \"Gender\", \"NativeCountry\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte = pd.get_dummies(Xte, columns=[\n",
    "    \"WorkClass\", \"MaritalStatus\", \"Occupation\", \"Relationship\",\n",
    "    \"Race\", \"Gender\", \"NativeCountry\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.insert(loc=65, column='NativeCountry_ Holand-Netherlands', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xva.insert(loc=66, column='WorkClass_ Never-worked', value=0)\n",
    "Xva.insert(loc=67, column='NativeCountry_ Cambodia', value=0)\n",
    "Xva.insert(loc=68, column='NativeCountry_ Honduras', value=0)\n",
    "Xva.insert(loc=69, column='NativeCountry_ Hungary', value=0)\n",
    "Xva.insert(loc=70, column='NativeCountry_ Scotland', value=0)\n",
    "Xva.insert(loc=71, column='NativeCountry_ Trinadad&Tobago', value=0)\n",
    "Xva.insert(loc=65, column='NativeCountry_ Holand-Netherlands', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.Age = Xtr.Age.astype(float)\n",
    "Xtr.EducationNum = Xtr.EducationNum.astype(float)\n",
    "Xtr.HoursPerWeek = Xtr.HoursPerWeek.astype(float)\n",
    "\n",
    "Xva.Age = Xva.Age.astype(float)\n",
    "Xva.EducationNum = Xva.EducationNum.astype(float)\n",
    "Xva.HoursPerWeek = Xva.HoursPerWeek.astype(float)\n",
    "\n",
    "Xte.Age = Xte.Age.astype(float)\n",
    "Xte.EducationNum = Xte.EducationNum.astype(float)\n",
    "Xte.HoursPerWeek = Xte.HoursPerWeek.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "# also try without standardizing the results\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "def standardization(X):\n",
    "    \n",
    "    Xscaler = X.filter([\"Age\", \"EducationNum\", \"HoursPerWeek\"],axis=1)\n",
    "    array = Xscaler.values\n",
    "    scaler = StandardScaler().fit(Xscaler)\n",
    "    rescaledX = scaler.transform(Xscaler)\n",
    "    return rescaledX\n",
    "\n",
    "Xtr_scaled = standardization(Xtr)\n",
    "Xtr.Age = Xtr_scaled[:,0]\n",
    "Xtr.EducationNum = Xtr_scaled[:,1]\n",
    "Xtr.HoursPerWeek = Xtr_scaled[:,2]\n",
    "\n",
    "Xva_scaled = standardization(Xva)\n",
    "Xva.Age = Xva_scaled[:,0]\n",
    "Xva.EducationNum = Xva_scaled[:,1]\n",
    "Xva.HoursPerWeek = Xva_scaled[:,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also try without normalizing the results\n",
    "def normalization(X):\n",
    "    Xnormal = X.filter([\"CapitalGain\",\"CapitalLoss\"],axis=1)\n",
    "    scaler = Normalizer().fit(Xnormal)\n",
    "    normalizedX = scaler.transform(Xnormal)\n",
    "    return normalizedX\n",
    "\n",
    "Xtr_normal = normalization(Xtr)\n",
    "Xtr.CapitalGain = Xtr_normal[:,0]\n",
    "Xtr.CapitalLoss = Xtr_normal[:,1]\n",
    "\n",
    "Xva_normal = normalization(Xva)\n",
    "Xva.CapitalGain= Xva_normal[:,0]\n",
    "Xva.CapitalLoss= Xva_normal[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation\n",
      "0.5273926532869324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "# kfold = model_selection.KFold(n_splits=7,random_state=7)\n",
    "randomForest = RandomForestClassifier(n_estimators=100)\n",
    "# cv_result = model_selection.cross_val_score(randomForest,Xtr,Ytr,cv=kfold,scoring='accuracy')\n",
    "score=randomForest.fit(Xtr,Ytr)\n",
    "YvaHat=score.predict(Xva)\n",
    "acc_score=roc_auc_score(Yva, YvaHat)\n",
    "# prediction = randomForest.predict(Xva)\n",
    "# acc_score = accuracy_score(Yva,prediction)\n",
    "# prediction1 = randomForest.predict(Xte)\n",
    "# acc_score1 = accuracy_score(Yte,prediction1)\n",
    "print(\"For validation\")\n",
    "print(acc_score)\n",
    "# print(\"For test\")\n",
    "# print(acc_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
